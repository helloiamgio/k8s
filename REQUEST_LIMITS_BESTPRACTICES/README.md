# Kubernetes CPU Limit â€” Best Practices per Prestazioni Ottimali

Basato sullâ€™articolo di PerfectScale *â€œKubernetes CPU Limit: Best Practices for Optimal Performanceâ€*, questa guida spiega come funzionano i **limiti e le richieste CPU** in Kubernetes, come influiscono sullo scheduling, e come configurarli correttamente per evitare colli di bottiglia o sprechi di risorse.

---

## Indice

1. Introduzione  
2. Differenza tra CPU Request e CPU Limit  
3. Come Kubernetes gestisce la CPU  
4. Problemi causati da limiti CPU troppo bassi o troppo alti  
5. Best Practices per i limiti CPU  
6. Esempi YAML e scenari pratici  
7. Monitoraggio e ottimizzazione continua  
8. Conclusioni  
9. Riferimenti

---

## 1. Introduzione

Le risorse CPU in Kubernetes vengono gestite tramite **request** e **limit**.  
Definire correttamente questi valori Ã¨ fondamentale per garantire che i pod abbiano prestazioni costanti senza compromettere la stabilitÃ  del cluster.


Unâ€™errata configurazione dei limiti CPU puÃ² portare a fenomeni come:

- **CPU throttling** (limitazione forzata della CPU da parte del kernel)
- **Underutilization** (uso inefficiente delle risorse)
- **InstabilitÃ  nei pod critici**

---

## 2. Differenza tra CPU Request e CPU Limit

| Tipo | Descrizione | Effetto |
|------|--------------|----------|
| **Request** | QuantitÃ  minima di CPU garantita al pod | Usata dallo scheduler per decidere dove posizionare il pod |
| **Limit** | QuantitÃ  massima di CPU che il pod puÃ² utilizzare | Imposta un limite rigido oltre il quale il container viene throttled |

> âš™ï¸ *Se un container supera il suo CPU limit, il kernel limita la frequenza della CPU, causando rallentamenti visibili nellâ€™applicazione.*

---

## 3. Come Kubernetes gestisce la CPU

Kubernetes non â€œprenotaâ€ la CPU come la memoria, ma utilizza il **CPU share model** del kernel Linux.  
Quando il cluster ha carichi elevati, il tempo CPU viene diviso tra i pod in base ai loro **CPU shares**, determinati dalla `request`.


### Comportamento chiave

- Se **limit = request**, il container ha CPU fissa e predicibile.  
- Se **limit > request**, il container puÃ² â€œburstareâ€ temporaneamente, ma puÃ² subire throttling.  
- Se **limit non Ã¨ impostato**, il container puÃ² consumare tutta la CPU del nodo finchÃ© Ã¨ disponibile.

---

## 4. Problemi causati da limiti CPU errati

### a. Limiti troppo bassi

- Il container viene throttled spesso, causando **latenze elevate**.  
- Performance degradate anche con risorse disponibili.

### b. Limiti troppo alti o assenti

- Il pod puÃ² monopolizzare la CPU del nodo, causando **starvation** ad altri pod.  
- DifficoltÃ  di scheduling in ambienti condivisi.

### c. Differenza eccessiva tra `request` e `limit`

- PuÃ² causare sbilanciamento nel cluster e comportamenti imprevedibili sotto carico.

---

## 5. Best Practices per i limiti CPU

### ğŸ”¹ 1. Evita di impostare limiti CPU rigidi per pod critici

Lascia che i pod critici possano utilizzare piÃ¹ CPU in caso di necessitÃ , impostando solo `requests` senza `limits`.

### ğŸ”¹ 2. Imposta richieste realistiche

Basati su dati reali raccolti da Prometheus o strumenti come PerfectScale.

```yaml
resources:
  requests:
    cpu: "250m"
  limits:
    cpu: "500m"
```

### ğŸ”¹ 3. Non usare gli stessi valori per tutti i pod

Ogni workload ha comportamenti diversi â€” adatta i limiti in base al profilo di utilizzo.

### ğŸ”¹ 4. Usa strumenti di autoscaling

Kubernetes HPA (Horizontal Pod Autoscaler) e VPA (Vertical Pod Autoscaler) aiutano a mantenere un equilibrio dinamico.

### ğŸ”¹ 5. Monitora i throttling event

Usa metriche come:  
```promql
rate(container_cpu_cfs_throttled_seconds_total[5m])
```
per rilevare quando i container vengono limitati.

---

## 6. Esempi YAML e scenari pratici

### Esempio 1 â€” Pod con limiti troppo rigidi

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: throttled-pod
spec:
  containers:
  - name: throttled
    image: nginx
    resources:
      requests:
        cpu: "200m"
      limits:
        cpu: "200m"
```

> âŒ In questo caso, se lâ€™applicazione necessita di piÃ¹ CPU, verrÃ  immediatamente throttled.

### Esempio 2 â€” Configurazione bilanciata

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: balanced-app
spec:
  replicas: 3
  template:
    spec:
      containers:
      - name: app
        image: myapp:v2
        resources:
          requests:
            cpu: "500m"
          limits:
            cpu: "1"
```

> âœ… Buon equilibrio tra garanzia e flessibilitÃ .

---

## 7. Monitoraggio e ottimizzazione continua

Strumenti consigliati da PerfectScale:

- **Prometheus + Grafana** â†’ per visualizzare CPU usage e throttling
- **Vertical Pod Autoscaler** â†’ per suggerimenti automatici sulle risorse
- **PerfectScale** â†’ analizza pattern di utilizzo e suggerisce limiti ottimali


---

## 8. Conclusioni

Un corretto bilanciamento tra *requests* e *limits* Ã¨ essenziale per:

- Evitare sprechi di CPU  
- Prevenire throttling eccessivo  
- Ottimizzare i costi del cluster  
- Garantire prestazioni stabili e prevedibili

> ğŸ¯ *â€œGestire correttamente i limiti CPU Ã¨ come regolare il motore di unâ€™auto: troppo basso e non parte, troppo alto e si surriscalda.â€*

---

## 9. Riferimenti

- PerfectScale Blog â€” [Kubernetes CPU Limit: Best Practices](https://www.perfectscale.io/blog/kubernetes-cpu-limit-best-practises)  
- Kubernetes Docs â€” [Resource Management for Pods and Containers](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/)

---

*Fine del file*.
